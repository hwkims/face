# Real-time Face Landmark Detection with Audio Pitch Control (face)

[![GitHub](https://img.shields.io/badge/GitHub-hwkims-blue?logo=github)](https://github.com/hwkims)
![image](https://github.com/user-attachments/assets/8e7a2dfb-f130-461e-945e-518d7364f435)

This project demonstrates real-time face landmark detection using a webcam feed. It utilizes **TensorFlow.js** with the **MediaPipe Face Mesh** model to detect 468 detailed facial landmarks.

The primary interaction involves **controlling the pitch (frequency) of a sine wave sound based on how wide the user opens their mouth**. The detected face mesh is also visualized on the HTML Canvas overlay.

The entire application is self-contained within a single HTML file.

*(Consider adding a screenshot or GIF of the demo here!)*
*`![Demo Screenshot](link_to_your_screenshot.png)`*

## ‚ú® Features

*   **Real-time Face Detection:** Identifies faces in the webcam feed.
*   **Detailed Landmark Tracking:** Tracks 468 facial landmarks using TensorFlow.js and MediaPipe Face Mesh (`refineLandmarks: true`).
*   **Face Mesh Visualization:** Draws the detected facial structure using landmark triangulation.
*   **Mouth Opening Detection:** Calculates the distance between the upper and lower lip landmarks.
*   **Interactive Audio Pitch Control:** Maps the mouth opening distance to the frequency of a sine wave generated by the **Web Audio API**. Opening the mouth wider changes the sound's pitch in real-time.
*   **Dynamic Audio Handling:** Sound only plays when a face is detected and requires user interaction (a click) to start initially due to browser policies.
*   **Client-Side Implementation:** Runs entirely within the user's web browser.
*   **Single File:** All code (HTML, CSS, JavaScript) is included in one `.html` file.

## üõ†Ô∏è Technologies Used

*   **HTML5:** Canvas API, WebRTC (`getUserMedia` for webcam access)
*   **CSS3:** Basic styling and layout.
*   **JavaScript (ES6+):** Core application logic.
*   **TensorFlow.js (`@tensorflow/tfjs`):** Core machine learning library.
    *   `@tensorflow/tfjs-backend-webgl`: WebGL backend for GPU acceleration.
*   **TensorFlow.js Models (`@tensorflow-models/face-landmarks-detection`):** Pre-trained MediaPipe Face Mesh model.
*   **Web Audio API:** For generating and controlling synthesized sounds (sine waves) directly in the browser.

## üöÄ How to Run

1.  **Clone or Download:**
    *   Clone this repository:
        ```bash
        git clone https://github.com/hwkims/face.git
        cd face
        ```
    *   Or, download the main HTML file (e.g., `face_sound.html` or `index.html`) directly.

2.  **Run a Local Web Server:**
    *   **‚ö†Ô∏è Important:** You **must** run this HTML file from a local web server due to browser security policies regarding webcam access (`getUserMedia`) and potentially model loading. Opening the file directly via `file://` protocol will **not** work.
    *   **Option 1: Using Python 3**
        ```bash
        # Navigate to the directory containing the HTML file in your terminal
        python -m http.server
        ```
        Then open your browser to `http://localhost:8000` (or the port shown).
    *   **Option 2: Using Node.js and `http-server`**
        ```bash
        # Install http-server globally if you haven't already: npm install -g http-server
        # Navigate to the directory containing the HTML file
        http-server .
        ```
        Then open your browser to the address shown (e.g., `http://127.0.0.1:8080`).
    *   **Option 3: Using VS Code's Live Server Extension**
        *   Install the "Live Server" extension in Visual Studio Code.
        *   Open the project folder in VS Code.
        *   Right-click the HTML file and select "Open with Live Server".

3.  **Open in Browser:**
    *   Navigate to the local server address provided by your chosen method.

4.  **Grant Camera Permission:**
    *   Allow the browser to access your webcam when prompted.

5.  **Enable Audio (Click):**
    *   Click anywhere on the page once. This is often required by browsers to enable audio playback.

6.  **Interact:**
    *   Position your face in front of the webcam. You should see a green mesh overlay on your face.
    *   **Slowly open and close your mouth.** You should hear a sine wave sound whose pitch changes according to how wide your mouth is open. The sound will stop if your face is no longer detected.

## üìù How Pitch Control Works

1.  The application continuously detects 468 face landmarks.
2.  It specifically tracks the landmarks for the center of the upper lip (`index 13`) and the center of the lower lip (`index 14`).
3.  The Euclidean distance between these two landmarks is calculated in each frame.
4.  This distance is normalized to a range of [0, 1] based on predefined minimum (`minMouthOpenDist`) and maximum (`maxMouthOpenDist`) expected distances (these might need tuning).
5.  The normalized distance is used to linearly interpolate a frequency value between a minimum (`minFreq`) and maximum (`maxFreq`) frequency.
6.  The frequency of the Web Audio API's `OscillatorNode` is smoothly updated to this calculated frequency using `setTargetAtTime`.

## üí° Notes & Considerations

*   **Performance:** Detection speed depends on your device's hardware.
*   **Lighting:** Good lighting improves detection accuracy.
*   **Audio Context:** Requires user interaction (click) to start due to browser autoplay policies.
*   **Tuning:** The values for `minMouthOpenDist`, `maxMouthOpenDist`, `minFreq`, `maxFreq`, and `minConfidence` in the JavaScript code might need adjustment based on your camera, distance, and desired sensitivity/range. You can check the console for the raw `mouthDistance` values to help with tuning.
*   **Mirroring:** The video and canvas are flipped horizontally for a natural mirror effect.
*   **Single Face:** The current configuration (`maxFaces: 1`) only processes the first detected face.

## üìÑ License

(Optional: Add license information here. MIT License is common for such projects.)
Example: This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details (if you add one).

---

Feel free to experiment and modify the code!
