<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Aiming Reticle (TensorFlow.js v2)</title>
    <style>
        body {
            margin: 0; padding: 0; display: flex; justify-content: center; align-items: center;
            min-height: 100vh; background-color: #1a1a1a;
             overflow: hidden; font-family: system-ui, sans-serif;
        }
        #container {
            position: relative; width: 640px; height: 480px;
            border: 1px solid #444; background-color: #000; overflow: hidden;
            box-shadow: 0 4px 10px rgba(0,0,0,0.4);
        }
        #webcam {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            transform: scaleX(-1); /* Mirror mode */
            object-fit: cover; display: block;
        }
        #overlay {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            z-index: 10; pointer-events: none;
        }
        /* Reticle Styles - 파란색 */
        .reticle { stroke: rgba(0, 150, 255, 0.85); stroke-width: 2.5; fill: none; }
        .reticle-center-dot { fill: rgba(0, 150, 255, 0.95); }
        .reticle-group { transition: transform 0.04s linear; }

        /* Loading/Error Messages */
         #message {
            position: absolute; left: 50%; top: 50%; transform: translate(-50%, -50%);
            color: white; font-size: 1.1em; background-color: rgba(0, 0, 0, 0.8);
            padding: 18px 25px; border-radius: 6px; z-index: 20; text-align: center;
            display: block; max-width: 85%;
            box-shadow: 0 2px 8px rgba(0,0,0,0.6);
            border: 1px solid rgba(255, 255, 255, 0.1);
         }
         #message.error { background-color: rgba(220, 20, 60, 0.85); border: 1px solid rgba(255, 99, 71, 0.5); }
    </style>

    <!-- TensorFlow.js and BlazeFace scripts -->
    <!-- These will be loaded and executed before window.onload fires -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core@4.20.0/dist/tf-core.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.20.0/dist/tf-backend-webgl.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter@4.20.0/dist/tf-converter.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface@0.1.0/dist/blazeface.min.js"></script>

</head>
<body>
    <div id="container">
        <video id="webcam" autoplay muted playsinline width="640" height="480"></video>
        <svg id="overlay"></svg>
        <div id="message">페이지 및 리소스 로딩 중...</div>
    </div>

    <script>
        const videoElement = document.getElementById('webcam');
        const overlayElement = document.getElementById('overlay');
        const messageElement = document.getElementById('message');
        const containerElement = document.getElementById('container');
        let reticleGroup = null;
        let videoWidth = 640;
        let videoHeight = 480;
        let model = null; // BlazeFace model
        let isModelReady = false;
        let rafId = null; // To store requestAnimationFrame ID for potential cancellation
        let lastVideoTime = -1;


        // --- Message Handling ---
        function showMessage(msg, isError = false) {
            messageElement.innerHTML = msg;
            messageElement.className = isError ? 'error' : '';
            messageElement.style.display = 'block';
            if (isError) console.error(msg); else console.log(msg);
        }
        function hideMessage() {
            messageElement.style.display = 'none';
        }

        // --- Reticle Drawing ---
        function updateReticle(pixelX, pixelY, size = 45) {
            const mirroredPixelX = videoWidth - pixelX; // Mirror X

            if (!reticleGroup) {
                reticleGroup = document.createElementNS('http://www.w3.org/2000/svg', 'g');
                reticleGroup.classList.add('reticle-group');
                const halfSize = size / 2, lineOffset = 6, centerDotRadius = 3.5;
                const circle = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
                circle.classList.add('reticle'); circle.setAttribute('r', halfSize);
                const lineH = document.createElementNS('http://www.w3.org/2000/svg', 'line');
                lineH.classList.add('reticle'); lineH.setAttribute('x1', -halfSize - lineOffset); lineH.setAttribute('y1', 0); lineH.setAttribute('x2', halfSize + lineOffset); lineH.setAttribute('y2', 0);
                const lineV = document.createElementNS('http://www.w3.org/2000/svg', 'line');
                lineV.classList.add('reticle'); lineV.setAttribute('x1', 0); lineV.setAttribute('y1', -halfSize - lineOffset); lineV.setAttribute('x2', 0); lineV.setAttribute('y2', halfSize + lineOffset);
                const centerDot = document.createElementNS('http://www.w3.org/2000/svg', 'circle');
                centerDot.classList.add('reticle-center-dot'); centerDot.setAttribute('r', centerDotRadius);
                reticleGroup.append(circle, lineH, lineV, centerDot);
                overlayElement.appendChild(reticleGroup);
            }
            reticleGroup.setAttribute('transform', `translate(${mirroredPixelX}, ${pixelY})`);
            reticleGroup.style.display = '';
        }

        function hideReticle() {
            if (reticleGroup) reticleGroup.style.display = 'none';
        }

        // --- Initialize TF.js and Load BlazeFace Model ---
        async function initializeTfAndModel() {
            showMessage('TensorFlow.js 및 모델 초기화 중...');
            console.log("Checking for TF.js and BlazeFace objects...");

            // Explicit check right before initialization attempt
            if (typeof tf === 'undefined' || typeof blazeface === 'undefined') {
                 const errorMsg = 'TensorFlow.js 또는 BlazeFace 라이브러리가 로드되지 않았습니다. 브라우저 개발자 도구의 네트워크 탭에서 스크립트 로딩 실패 여부를 확인하세요.';
                 showMessage(errorMsg, true);
                 return false; // Stop initialization
            }
            console.log("TF.js and BlazeFace objects found.");

            try {
                 await tf.setBackend('webgl');
                 await tf.ready();
                 console.log(`Using TF.js backend: ${tf.getBackend()}`);

                 model = await blazeface.load();
                 isModelReady = true;
                 showMessage('모델 준비 완료. 카메라 시작 중...');
                 console.log('BlazeFace model loaded successfully.');
                 return true;
            } catch (error) {
                 let errorMsg = `모델 초기화 중 오류 발생: ${error.message}`;
                 if (error.message.toLowerCase().includes('webgl')) {
                     errorMsg += '<br>WebGL 초기화에 실패했습니다. 브라우저 또는 그래픽 드라이버 설정을 확인하세요.';
                 } else {
                     errorMsg += '<br>자세한 내용은 브라우저 콘솔을 확인하세요.';
                 }
                 showMessage(errorMsg, true);
                 return false;
            }
        }

        // --- Start Webcam ---
        async function startWebcam() {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                showMessage('오류: 웹캠 접근(getUserMedia)을 지원하지 않는 브라우저입니다.', true);
                return false;
            }
            try {
                showMessage('카메라 접근 권한 요청 중...');
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: { width: { exact: 640 }, height: { exact: 480 }, facingMode: 'user' },
                    audio: false
                });
                videoElement.srcObject = stream;

                return new Promise((resolve) => {
                    videoElement.onloadedmetadata = () => {
                        videoWidth = videoElement.videoWidth;
                        videoHeight = videoElement.videoHeight;
                        containerElement.style.width = `${videoWidth}px`;
                        containerElement.style.height = `${videoHeight}px`;
                        overlayElement.setAttribute('viewBox', `0 0 ${videoWidth} ${videoHeight}`);
                        console.log(`카메라 시작됨. 비디오 크기: ${videoWidth}x${videoHeight}`);
                        showMessage('카메라 준비 완료. 감지 시작.');
                        setTimeout(hideMessage, 1500);
                        resolve(true);
                    };
                    videoElement.onerror = (e) => {
                         showMessage(`비디오 오류: ${e.message || '알 수 없는 오류'}`, true);
                         resolve(false);
                     }
                });
            } catch (error) {
                 let msg = `카메라 접근 실패: ${error.name} - ${error.message}`;
                 if (error.name === "NotAllowedError") msg = "카메라 접근 권한이 거부되었습니다.";
                 else if (error.name === "NotFoundError") msg = "지정한 해상도(640x480)를 지원하는 카메라를 찾을 수 없습니다.";
                 else if (error.name === "OverconstrainedError") msg = "지정한 해상도(640x480)를 카메라가 지원하지 않습니다.";
                 else if (error.name === "NotReadableError") msg = "카메라를 사용할 수 없습니다. 다른 프로그램에서 사용 중인지 확인하세요.";
                 showMessage(msg, true);
                 return false;
            }
        }

        // --- Prediction Loop ---
        async function predictWebcam() {
            if (!isModelReady || videoElement.readyState < videoElement.HAVE_METADATA) {
                rafId = requestAnimationFrame(predictWebcam);
                return;
            }

            if (videoElement.paused || videoElement.ended) {
                console.log("Video stopped, stopping prediction loop.");
                hideReticle();
                return; // Stop the loop if video is paused or ended
            }

             // Throttle using currentTime only if needed and reliable
             // if (videoElement.currentTime === lastVideoTime) {
             //     rafId = requestAnimationFrame(predictWebcam);
             //     return;
             // }
             // lastVideoTime = videoElement.currentTime;

            try {
                // Use a flag to prevent re-entry if prediction takes longer than a frame
                if (videoElement.readyState >= videoElement.HAVE_CURRENT_DATA) { // Check if current frame data is available
                    tf.tidy(() => {
                        // estimateFaces can sometimes throw if video frame is not ready
                        const predictions = model.estimateFaces(videoElement, false, false);

                        if (predictions && predictions.length > 0) {
                            const face = predictions[0];
                            const topLeft = face.topLeft;
                            const bottomRight = face.bottomRight;
                            const centerX = topLeft[0] + (bottomRight[0] - topLeft[0]) / 2;
                            const centerY = topLeft[1] + (bottomRight[1] - topLeft[1]) / 2;
                            updateReticle(centerX, centerY);
                        } else {
                            hideReticle();
                        }
                    }); // End tf.tidy
                } else {
                    // If no current data, maybe wait a bit or just skip this frame
                    hideReticle(); // Hide if we can't process the frame
                }

            } catch (error) {
                 console.error("Error during face detection:", error);
                 hideReticle(); // Hide reticle on error
            }

            rafId = requestAnimationFrame(predictWebcam); // Continue the loop
        }

        // --- Cleanup ---
        function stopPrediction() {
             if (rafId) {
                 cancelAnimationFrame(rafId);
                 rafId = null;
             }
             // Optional: Stop webcam stream
             // if (videoElement.srcObject) {
             //     videoElement.srcObject.getTracks().forEach(track => track.stop());
             //     videoElement.srcObject = null;
             // }
             console.log("Prediction loop stopped.");
        }


        // --- Main Execution ---
        async function run() {
            showMessage('모든 리소스 로드 완료. 초기화 시작...');
            const modelInitialized = await initializeTfAndModel();
            if (modelInitialized) {
                const webcamStarted = await startWebcam();
                if (webcamStarted) {
                    // Start prediction loop only if both model and webcam are ready
                    predictWebcam(); // Initial call to start the loop
                } else {
                     showMessage("웹캠 시작 실패. 애플리케이션을 사용할 수 없습니다.", true);
                 }
            } else {
                 showMessage("모델 초기화 실패. 애플리케이션을 사용할 수 없습니다.", true);
            }
        }

        // Use window.onload to ensure scripts are loaded and ready
        window.addEventListener('load', run);

        // Optional: Add cleanup listener for when the page is closed/hidden
        // window.addEventListener('beforeunload', stopPrediction);
        // document.addEventListener('visibilitychange', () => {
        //     if (document.hidden) {
        //         stopPrediction();
        //     } else if (isModelReady && videoElement.srcObject) {
        //         // Optionally restart prediction if needed when tab becomes visible again
        //         // predictWebcam();
        //     }
        // });

    </script>

</body>
</html>
