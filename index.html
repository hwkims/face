<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>얼굴 표정 인식 & 사운드 컨트롤 (수정)</title>
    <style>
        /* ... CSS는 이전과 동일 ... */
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; margin: 0; padding: 20px; background-color: #f0f0f0; }
        #container { position: relative; width: 640px; height: 480px; border: 1px solid black; margin-bottom: 15px; background-color: #333; }
        #video { display: none; width: 100%; height: 100%; transform: scaleX(-1); }
        #canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; transform: scaleX(-1); }
        #status { font-weight: bold; color: #333; margin-bottom: 10px; }
        p { text-align: center; }
    </style>
    <!-- TensorFlow.js 라이브러리 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <!-- Face Landmark Detection 모델 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
</head>
<body>
    <h1>얼굴 표정 인식 & 사운드 컨트롤 (수정)</h1>
    <p>카메라에 얼굴을 보여주세요.<br>입을 벌리면 소리의 높낮이가 변합니다!<br><b>(F12를 눌러 콘솔 확인)</b></p>

    <div id="container">
        <video id="video" playsinline></video>
        <canvas id="canvas"></canvas>
    </div>
    <div id="status">카메라 및 모델 준비 중...</div>

    <script>
        console.log("스크립트 시작");

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const statusDiv = document.getElementById('status');

        let detector;
        let audioContext;
        let oscillator;
        let gainNode;
        let isAudioSetup = false;
        let isAudioPlaying = false;
        const minConfidence = 0.7; // 신뢰도 임계값

        const minMouthOpenDist = 3;
        const maxMouthOpenDist = 35;
        const minFreq = 110;
        const maxFreq = 880;

        const UPPER_LIP_CENTER = 13;
        const LOWER_LIP_CENTER = 14;

        // --- Web Audio API 설정 (변경 없음) ---
        function initAudio() { /* ... 이전과 동일 ... */
            console.log("initAudio() 호출됨"); try { window.AudioContext = window.AudioContext || window.webkitAudioContext; audioContext = new AudioContext(); console.log("AudioContext 생성됨. 상태:", audioContext.state); oscillator = audioContext.createOscillator(); gainNode = audioContext.createGain(); oscillator.type = 'sine'; oscillator.frequency.setValueAtTime(minFreq, audioContext.currentTime); gainNode.gain.setValueAtTime(0, audioContext.currentTime); oscillator.connect(gainNode); gainNode.connect(audioContext.destination); isAudioSetup = true; statusDiv.innerText = "오디오 준비 완료. 카메라/모델 로딩 중..."; console.log("오디오 노드 설정 완료"); document.body.addEventListener('click', resumeAudioContext, { once: true }); console.log("오디오 재개 리스너 추가됨"); } catch (e) { console.error("Web Audio API 초기화 실패:", e); statusDiv.innerText = "오류: Web Audio API 초기화 실패."; isAudioSetup = false; }
        }
        function resumeAudioContext() { /* ... 이전과 동일 ... */
            console.log("resumeAudioContext() 호출됨. 현재 상태:", audioContext?.state); if (audioContext && audioContext.state === 'suspended') { audioContext.resume().then(() => { console.log('AudioContext 재개 성공. 새 상태:', audioContext.state); if (isAudioSetup && !isAudioPlaying) { try { oscillator.start(); isAudioPlaying = true; console.log("오실레이터 시작됨 (재개 후)."); } catch (startError) { console.error("오실레이터 시작 오류 (재개 후):", startError); } } }).catch(e => console.error('AudioContext 재개 오류:', e)); } else if (isAudioSetup && !isAudioPlaying && audioContext && audioContext.state === 'running') { try { oscillator.start(); isAudioPlaying = true; console.log("오실레이터 시작됨 (이미 실행 중)."); } catch (startError) { console.error("오실레이터 시작 오류 (이미 실행 중):", startError); } }
        }
        function startAudio() { /* ... 이전과 동일 ... */
            console.log("startAudio() 호출됨. isAudioSetup:", isAudioSetup, "isAudioPlaying:", isAudioPlaying, "AC State:", audioContext?.state); if (isAudioSetup && isAudioPlaying && gainNode) { gainNode.gain.setTargetAtTime(0.5, audioContext.currentTime, 0.1); console.log("오디오 볼륨 높임 (재개)"); } else if (isAudioSetup && !isAudioPlaying && audioContext && audioContext.state === 'running') { try { if (!isAudioPlaying) oscillator.start(); isAudioPlaying = true; gainNode.gain.setTargetAtTime(0.5, audioContext.currentTime, 0.1); console.log("오디오 시작 및 볼륨 높임 (명시적 호출)."); } catch (e) { console.warn("startAudio에서 오실레이터 시작 실패:", e); } } else if (isAudioSetup && !isAudioPlaying && audioContext && audioContext.state === 'suspended') { console.log("오디오 컨텍스트가 suspended 상태입니다. 페이지를 클릭하세요."); statusDiv.innerText = "오디오 활성화를 위해 화면을 클릭하세요."; }
        }
        function stopAudio() { /* ... 이전과 동일 ... */
             console.log("stopAudio() 호출됨. isAudioSetup:", isAudioSetup); if (isAudioSetup && gainNode) { gainNode.gain.setTargetAtTime(0, audioContext.currentTime, 0.2); console.log("오디오 볼륨 낮춤."); }
        }
        function updateFrequency(mouthOpenDistance) { /* ... 이전과 동일 ... */
             if (!isAudioSetup || !isAudioPlaying) return; let normalizedDist = (mouthOpenDistance - minMouthOpenDist) / (maxMouthOpenDist - minMouthOpenDist); normalizedDist = Math.max(0, Math.min(1, normalizedDist)); const frequency = minFreq + normalizedDist * (maxFreq - minFreq); oscillator.frequency.setTargetAtTime(frequency, audioContext.currentTime, 0.05);
        }

        // --- 웹캠 설정 (변경 없음) ---
        async function setupCamera() { /* ... 이전과 동일 ... */
            console.log("setupCamera() 호출됨"); try { const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: false }); video.srcObject = stream; console.log("카메라 스트림 가져옴"); return new Promise((resolve) => { video.onloadedmetadata = () => { console.log("비디오 메타데이터 로드됨"); video.width = video.videoWidth; video.height = video.videoHeight; canvas.width = video.videoWidth; canvas.height = video.videoHeight; resolve(video); }; }); } catch (error) { console.error("카메라 접근 오류:", error); statusDiv.innerText = "오류: 카메라 접근 불가"; alert("카메라 권한 허용 필요"); throw error; }
        }

        // --- Face Landmark Detection 모델 로드 (변경 없음) ---
        async function loadDetector() { /* ... 이전과 동일 ... */
             console.log("loadDetector() 호출됨"); try { statusDiv.innerText = "TF.js 백엔드 준비 중..."; await tf.ready(); console.log("TF.js 백엔드 준비 완료"); statusDiv.innerText = "얼굴 인식 모델 로딩 중..."; const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh; const detectorConfig = { runtime: 'tfjs', refineLandmarks: true, maxFaces: 1 }; detector = await faceLandmarksDetection.createDetector(model, detectorConfig); console.log("얼굴 인식 모델 로드 성공:", detector); statusDiv.innerText = "모델 로드 완료. 감지를 시작합니다."; } catch (error) { console.error("모델 로드 오류:", error); statusDiv.innerText = "오류: 얼굴 인식 모델 로드 실패."; detector = null; throw error; }
        }

        // --- 얼굴 감지 및 그리기 루프 (수정됨) ---
        let faceDetectedLastFrame = false;
        let frameCount = 0;

        async function detectFaces() {
             frameCount++;

            if (!detector || video.readyState < 3) {
                 if (frameCount % 60 === 0) { console.log(`대기 중... Detector: ${!!detector}, Video ReadyState: ${video.readyState}`); }
                 requestAnimationFrame(detectFaces);
                 return;
            }

            let faceDetectedThisFrame = false;
            try {
                const faces = await detector.estimateFaces(video, { flipHorizontal: false });

                // --- 그리기 시작 ---
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                // --- 그리기 끝 ---

                if (faces && faces.length > 0) {
                    const face = faces[0];

                    // ================== 수정된 부분 시작 ==================
                    // face.box.score 대신 face.score 를 확인합니다.
                    if (typeof face.score === 'number') { // score가 숫자인지 확인
                        if (frameCount % 60 === 0) { // 로그 확인
                             console.log(`프레임 ${frameCount}: 감지된 얼굴 수 = ${faces.length}, 첫 번째 얼굴 신뢰도: ${face.score}`);
                        }

                        if (face.score >= minConfidence) { // 신뢰도 임계값과 비교
                            faceDetectedThisFrame = true;
                            drawFaceMesh(face.keypoints); // 얼굴 메쉬 그리기

                            // 입 벌림 거리 계산 및 주파수 업데이트
                            const upperLip = face.keypoints[UPPER_LIP_CENTER];
                            const lowerLip = face.keypoints[LOWER_LIP_CENTER];
                            if (upperLip && lowerLip) {
                                const mouthDistance = Math.sqrt(Math.pow(upperLip.x - lowerLip.x, 2) + Math.pow(upperLip.y - lowerLip.y, 2));
                                updateFrequency(mouthDistance);
                            }
                        } else {
                             if (frameCount % 60 === 0) console.log(`얼굴 감지됨 (신뢰도 낮음: ${face.score})`);
                        }
                    } else {
                         // score 속성 자체가 없거나 숫자가 아닌 경우
                         if (frameCount % 60 === 0) {
                              console.warn(`프레임 ${frameCount}: 감지된 얼굴에 유효한 score 속성 없음. face 객체:`, face);
                              // 여기서 face 객체 전체를 보면 다른 위치에 score 정보가 있는지 확인할 수 있습니다.
                         }
                         // score가 없으면 얼굴이 감지되지 않은 것으로 간주하거나, 다른 기준 사용 필요
                    }
                    // ================== 수정된 부분 끝 ====================

                } else {
                     if (frameCount % 60 === 0) console.log(`프레임 ${frameCount}: 얼굴 감지 안됨`);
                }

                // 오디오 제어
                if (faceDetectedThisFrame && !faceDetectedLastFrame) {
                    startAudio();
                } else if (!faceDetectedThisFrame && faceDetectedLastFrame) {
                    stopAudio();
                }
                faceDetectedLastFrame = faceDetectedThisFrame;

            } catch (error) {
                console.error("detectFaces 루프 내 오류:", error);
                faceDetectedLastFrame = false;
                stopAudio();
            }

            requestAnimationFrame(detectFaces);
        }

        // 얼굴 메쉬 그리기 (변경 없음)
        function drawFaceMesh(keypoints) { /* ... 이전과 동일 ... */
            ctx.strokeStyle = 'rgba(0, 255, 0, 0.5)'; ctx.lineWidth = 0.5; const triangles = faceLandmarksDetection.util.TRIANGULATION; for (let i = 0; i < triangles.length / 3; i++) { const kptIndex1 = triangles[i * 3], kptIndex2 = triangles[i * 3 + 1], kptIndex3 = triangles[i * 3 + 2]; const kp1 = keypoints[kptIndex1], kp2 = keypoints[kptIndex2], kp3 = keypoints[kptIndex3]; if (kp1 && kp2 && kp3) { ctx.beginPath(); ctx.moveTo(kp1.x, kp1.y); ctx.lineTo(kp2.x, kp2.y); ctx.lineTo(kp3.x, kp3.y); ctx.closePath(); ctx.stroke(); } }
        }


        // --- 메인 실행 함수 (변경 없음) ---
        async function main() { /* ... 이전과 동일 ... */
             console.log("main() 함수 시작"); try { initAudio(); statusDiv.innerText = "카메라 접근 권한 요청 중..."; await setupCamera(); statusDiv.innerText = "카메라 준비 완료. 비디오 재생 시도..."; try { await video.play(); console.log("비디오 재생 시작됨."); } catch (playError) { console.error("비디오 자동 재생 실패:", playError); statusDiv.innerText = "비디오 재생 실패. 페이지와 상호작용 필요할 수 있음."; } await loadDetector(); if (detector) { detectFaces(); console.log("얼굴 감지 루프 시작됨"); } else { console.error("Detector가 로드되지 않아 감지를 시작할 수 없습니다."); statusDiv.innerText = "오류: 모델 로드 실패로 감지 시작 불가."; } } catch (error) { console.error("main 함수 초기화 실패:", error); statusDiv.innerText = "초기화 중 심각한 오류 발생."; }
        }

        // 페이지 로드 완료 후 메인 함수 실행 (변경 없음)
        window.addEventListener('load', () => { /* ... 이전과 동일 ... */
            console.log("페이지 로드 완료"); main();
        });

    </script>
</body>
</html>
