<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>얼굴/눈 인식 & 사운드 컨트롤 (수정)</title>
    <style>
        body { font-family: sans-serif; display: flex; flex-direction: column; align-items: center; margin: 0; padding: 20px; background-color: #f0f0f0; }
        #container { position: relative; width: 640px; height: 480px; border: 1px solid black; margin-bottom: 15px; background-color: #333; }
        #video { display: none; width: 100%; height: 100%; transform: scaleX(-1); }
        #canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; transform: scaleX(-1); }
        #status { font-weight: bold; color: #333; margin-bottom: 10px; }
        p { text-align: center; }
    </style>
    <!-- TensorFlow.js 라이브러리 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-core"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-converter"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl"></script>
    <!-- Face Landmark Detection 모델 -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
</head>
<body>
    <h1>얼굴/눈 인식 & 사운드 컨트롤 (수정)</h1>
    <p>카메라에 얼굴을 보여주세요.<br>입을 벌리면 소리 높낮이가 변하고, 눈을 깜빡이면 '뿅' 소리가 납니다.</p>

    <div id="container">
        <video id="video" playsinline></video>
        <canvas id="canvas"></canvas>
    </div>
    <div id="status">카메라 및 모델 준비 중...</div>

    <script>
        console.log("스크립트 시작");

        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');
        const statusDiv = document.getElementById('status');

        let detector;
        let audioContext;
        let mouthOscillator; // 입 벌림 제어용 오실레이터
        let mouthGainNode;   // 입 벌림 제어용 게인
        let isAudioSetup = false;
        let isMouthAudioPlaying = false; // 입 오디오 재생 상태

        // 입 벌림 관련 설정
        const minMouthOpenDist = 3;
        const maxMouthOpenDist = 35;
        const minFreq = 110; // A2
        const maxFreq = 880; // A5

        // 눈 깜빡임 관련 설정
        const EYE_BLINK_THRESHOLD = 6; // 눈꺼풀 거리 임계값 (튜닝 필요)
        const BLINK_SOUND_FREQ = 1200; // 눈 깜빡임 소리 주파수
        const BLINK_SOUND_DURATION = 0.08; // 눈 깜빡임 소리 지속 시간
        let canPlayBlinkSound = true;    // 눈 깜빡임 소리 쿨다운 플래그
        const blinkSoundCooldown = 300;  // 눈 깜빡임 소리 쿨다운 (ms)

        // MediaPipe Face Mesh Landmark Indices
        const UPPER_LIP_CENTER = 13;
        const LOWER_LIP_CENTER = 14;
        // 눈꺼풀 랜드마크 (예시, 정확한 인덱스는 모델/버전에 따라 다를 수 있음, MediaPipe 문서 참조)
        const LEFT_EYE_TOP = 159;
        const LEFT_EYE_BOTTOM = 145;
        const RIGHT_EYE_TOP = 386;
        const RIGHT_EYE_BOTTOM = 374;

        // --- Web Audio API 설정 ---
        function initAudio() {
            console.log("initAudio() 호출됨");
            try {
                window.AudioContext = window.AudioContext || window.webkitAudioContext;
                audioContext = new AudioContext();
                console.log("AudioContext 생성됨. 상태:", audioContext.state);

                // 입 벌림 오디오 설정
                mouthOscillator = audioContext.createOscillator();
                mouthGainNode = audioContext.createGain();
                mouthOscillator.type = 'sine';
                mouthOscillator.frequency.setValueAtTime(minFreq, audioContext.currentTime);
                mouthGainNode.gain.setValueAtTime(0, audioContext.currentTime); // 초기 볼륨 0
                mouthOscillator.connect(mouthGainNode);
                mouthGainNode.connect(audioContext.destination);

                isAudioSetup = true;
                statusDiv.innerText = "오디오 준비 완료. 카메라/모델 로딩 중...";
                console.log("오디오 노드 설정 완료");

                document.body.addEventListener('click', resumeAudioContext, { once: true });
                console.log("오디오 재개 리스너 추가됨");

            } catch (e) {
                console.error("Web Audio API 초기화 실패:", e);
                statusDiv.innerText = "오류: Web Audio API 초기화 실패.";
                isAudioSetup = false;
            }
        }

        function resumeAudioContext() {
            console.log("resumeAudioContext() 호출됨. 현재 상태:", audioContext?.state);
             if (audioContext && audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    console.log('AudioContext 재개 성공. 새 상태:', audioContext.state);
                    startMouthOscillatorIfNeeded(); // 입 오실레이터 시작
                }).catch(e => console.error('AudioContext 재개 오류:', e));
            } else if (isAudioSetup && audioContext && audioContext.state === 'running') {
                 startMouthOscillatorIfNeeded(); // 이미 실행 중이면 시작
            }
        }

        function startMouthOscillatorIfNeeded() {
             if (isAudioSetup && !isMouthAudioPlaying) {
                try {
                    mouthOscillator.start();
                    isMouthAudioPlaying = true;
                    console.log("입 오실레이터 시작됨.");
                } catch (startError) {
                    console.error("입 오실레이터 시작 오류:", startError);
                    if (startError.message.includes("already started")) isMouthAudioPlaying = true;
                }
            }
        }

        // 얼굴 감지 시 메인 오디오 시작 (볼륨 높이기)
        function startMainAudio() {
            if (isAudioSetup && isMouthAudioPlaying && mouthGainNode) {
                mouthGainNode.gain.setTargetAtTime(0.5, audioContext.currentTime, 0.1); // 부드럽게 볼륨 0.5로
                // console.log("메인 오디오 볼륨 높임"); // 확인 후 주석 처리
            }
        }

        // 얼굴 감지 안될 시 메인 오디오 중지 (볼륨 낮추기)
        function stopMainAudio() {
            if (isAudioSetup && mouthGainNode) {
                mouthGainNode.gain.setTargetAtTime(0, audioContext.currentTime, 0.2); // 부드럽게 볼륨 0으로
                // console.log("메인 오디오 볼륨 낮춤"); // 확인 후 주석 처리
            }
        }

        // 입 벌림 정도에 따라 주파수 조절
        function updateMouthFrequency(mouthOpenDistance) {
            if (!isAudioSetup || !isMouthAudioPlaying) return;
            let normalizedDist = (mouthOpenDistance - minMouthOpenDist) / (maxMouthOpenDist - minMouthOpenDist);
            normalizedDist = Math.max(0, Math.min(1, normalizedDist));
            const frequency = minFreq + normalizedDist * (maxFreq - minFreq);
            mouthOscillator.frequency.setTargetAtTime(frequency, audioContext.currentTime, 0.05);
        }

        // 눈 깜빡임 소리 재생
        function playBlinkSound() {
            if (!isAudioSetup || !canPlayBlinkSound || !audioContext) return;

            // 오디오 컨텍스트 상태 확인 및 재개 시도 (혹시 모르니)
             if (audioContext.state === 'suspended') {
                audioContext.resume().then(() => {
                    console.log("Blink sound: AudioContext resumed.");
                    actuallyPlayBlinkSound();
                }).catch(e => console.error("Blink sound: Error resuming AC:", e));
            } else {
                 actuallyPlayBlinkSound();
            }
        }

        function actuallyPlayBlinkSound() {
             canPlayBlinkSound = false; // 쿨다운 시작
             // console.log("눈 깜빡임 소리 재생!"); // 확인 후 주석 처리

             const blinkOscillator = audioContext.createOscillator();
             const blinkGainNode = audioContext.createGain();

             blinkOscillator.type = 'triangle'; // '뿅' 느낌을 위해 triangle 파형 사용
             blinkOscillator.frequency.setValueAtTime(BLINK_SOUND_FREQ, audioContext.currentTime);

             // 짧은 시간 동안 볼륨 올렸다가 내리기 (Attack-Decay)
             blinkGainNode.gain.setValueAtTime(0, audioContext.currentTime);
             blinkGainNode.gain.linearRampToValueAtTime(0.6, audioContext.currentTime + BLINK_SOUND_DURATION * 0.2); // 빠르게 Attack
             blinkGainNode.gain.exponentialRampToValueAtTime(0.01, audioContext.currentTime + BLINK_SOUND_DURATION); // Decay

             blinkOscillator.connect(blinkGainNode);
             blinkGainNode.connect(audioContext.destination);

             blinkOscillator.start(audioContext.currentTime);
             blinkOscillator.stop(audioContext.currentTime + BLINK_SOUND_DURATION);

             blinkOscillator.onended = () => {
                 blinkOscillator.disconnect();
                 blinkGainNode.disconnect();
                 // 쿨다운 해제
                 setTimeout(() => { canPlayBlinkSound = true; }, blinkSoundCooldown);
             };
        }

        // --- 웹캠 설정 (변경 없음) ---
        async function setupCamera() { /* ... 이전 디버깅 코드와 동일 ... */
            console.log("setupCamera() 호출됨"); try { const stream = await navigator.mediaDevices.getUserMedia({ video: { width: 640, height: 480 }, audio: false }); video.srcObject = stream; console.log("카메라 스트림 가져옴"); return new Promise((resolve) => { video.onloadedmetadata = () => { console.log("비디오 메타데이터 로드됨"); video.width = video.videoWidth; video.height = video.videoHeight; canvas.width = video.videoWidth; canvas.height = video.videoHeight; resolve(video); }; }); } catch (error) { console.error("카메라 접근 오류:", error); statusDiv.innerText = "오류: 카메라 접근 불가"; alert("카메라 권한 허용 필요"); throw error; }
        }

        // --- Face Landmark Detection 모델 로드 (변경 없음) ---
        async function loadDetector() { /* ... 이전 디버깅 코드와 동일 ... */
             console.log("loadDetector() 호출됨"); try { statusDiv.innerText = "TF.js 백엔드 준비 중..."; await tf.ready(); console.log("TF.js 백엔드 준비 완료"); statusDiv.innerText = "얼굴 인식 모델 로딩 중..."; const model = faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh; const detectorConfig = { runtime: 'tfjs', refineLandmarks: true, maxFaces: 1 }; detector = await faceLandmarksDetection.createDetector(model, detectorConfig); console.log("얼굴 인식 모델 로드 성공:", detector); statusDiv.innerText = "모델 로드 완료. 감지를 시작합니다."; } catch (error) { console.error("모델 로드 오류:", error); statusDiv.innerText = "오류: 얼굴 인식 모델 로드 실패."; detector = null; throw error; }
        }

        // 얼굴 메쉬 그리기 (변경 없음)
        function drawFaceMesh(keypoints) { /* ... 이전 디버깅 코드와 동일 ... */
            ctx.strokeStyle = 'rgba(0, 255, 0, 0.5)'; ctx.lineWidth = 0.5; const triangles = faceLandmarksDetection.util.TRIANGULATION; for (let i = 0; i < triangles.length / 3; i++) { const kptIndex1 = triangles[i * 3], kptIndex2 = triangles[i * 3 + 1], kptIndex3 = triangles[i * 3 + 2]; const kp1 = keypoints[kptIndex1], kp2 = keypoints[kptIndex2], kp3 = keypoints[kptIndex3]; if (kp1 && kp2 && kp3) { ctx.beginPath(); ctx.moveTo(kp1.x, kp1.y); ctx.lineTo(kp2.x, kp2.y); ctx.lineTo(kp3.x, kp3.y); ctx.closePath(); ctx.stroke(); } }
        }

        // --- 얼굴 감지 및 그리기 루프 (수정됨) ---
        let faceDetectedLastFrame = false;
        let frameCount = 0;

        async function detectFaces() {
             frameCount++;

            if (!detector || video.readyState < 3) {
                 if (frameCount % 60 === 0) console.log(`대기 중... Detector: ${!!detector}, Video ReadyState: ${video.readyState}`);
                 requestAnimationFrame(detectFaces);
                 return;
            }

            let faceDetectedThisFrame = false;

            try {
                const faces = await detector.estimateFaces(video, { flipHorizontal: false });

                // --- 그리기 시작 ---
                ctx.clearRect(0, 0, canvas.width, canvas.height);
                // 웹캠 영상 먼저 그리기!
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                // --- 그리기 끝 ---

                if (faces && faces.length > 0) {
                    const face = faces[0];

                    // keypoints 존재 여부로 얼굴 감지 판단 (Score 확인 생략)
                    if (face.keypoints && face.keypoints.length > 400) { // 468 또는 478개의 점이 있는지 대략 확인
                        faceDetectedThisFrame = true;

                        // 얼굴 메쉬 그리기
                        drawFaceMesh(face.keypoints);

                        // --- 입 벌림 감지 및 오디오 제어 ---
                        const upperLip = face.keypoints[UPPER_LIP_CENTER];
                        const lowerLip = face.keypoints[LOWER_LIP_CENTER];
                        if (upperLip && lowerLip) {
                            const mouthDistance = Math.sqrt(Math.pow(upperLip.x - lowerLip.x, 2) + Math.pow(upperLip.y - lowerLip.y, 2));
                            updateMouthFrequency(mouthDistance); // 주파수 업데이트
                        }

                        // --- 눈 깜빡임 감지 및 오디오 제어 ---
                        const leftEyeTop = face.keypoints[LEFT_EYE_TOP];
                        const leftEyeBottom = face.keypoints[LEFT_EYE_BOTTOM];
                        const rightEyeTop = face.keypoints[RIGHT_EYE_TOP];
                        const rightEyeBottom = face.keypoints[RIGHT_EYE_BOTTOM];

                        if (leftEyeTop && leftEyeBottom && rightEyeTop && rightEyeBottom) {
                            const leftEyeDist = Math.abs(leftEyeTop.y - leftEyeBottom.y); // Y 좌표 차이
                            const rightEyeDist = Math.abs(rightEyeTop.y - rightEyeBottom.y);
                            // console.log(`Eye Dist L: ${leftEyeDist.toFixed(1)}, R: ${rightEyeDist.toFixed(1)}`); // 값 확인 후 주석처리

                            // 양쪽 눈 중 하나라도 감기면 깜빡임으로 간주 (임계값 비교)
                            if (leftEyeDist < EYE_BLINK_THRESHOLD || rightEyeDist < EYE_BLINK_THRESHOLD) {
                                playBlinkSound(); // 눈 깜빡임 소리 재생 시도
                            }
                        }

                    } else {
                        // Keypoints가 없거나 부족하면 감지 실패로 간주
                         if (frameCount % 60 === 0) console.log(`프레임 ${frameCount}: 유효한 keypoints 없음`);
                    }
                } else {
                     if (frameCount % 60 === 0) console.log(`프레임 ${frameCount}: 얼굴 감지 안됨`);
                }

                // 오디오 제어 (메인 사운드 On/Off)
                if (faceDetectedThisFrame && !faceDetectedLastFrame) {
                    startMainAudio(); // 얼굴 나타나면 메인 소리 켜기
                } else if (!faceDetectedThisFrame && faceDetectedLastFrame) {
                    stopMainAudio(); // 얼굴 사라지면 메인 소리 끄기
                }
                faceDetectedLastFrame = faceDetectedThisFrame;

            } catch (error) {
                console.error("detectFaces 루프 내 오류:", error);
                faceDetectedLastFrame = false;
                stopMainAudio();
            }

            requestAnimationFrame(detectFaces);
        }


        // --- 메인 실행 함수 ---
        async function main() { /* ... 이전 디버깅 코드와 동일 ... */
             console.log("main() 함수 시작"); try { initAudio(); statusDiv.innerText = "카메라 접근 권한 요청 중..."; await setupCamera(); statusDiv.innerText = "카메라 준비 완료. 비디오 재생 시도..."; try { await video.play(); console.log("비디오 재생 시작됨."); } catch (playError) { console.error("비디오 자동 재생 실패:", playError); statusDiv.innerText = "비디오 재생 실패. 페이지와 상호작용 필요할 수 있음."; } await loadDetector(); if (detector) { detectFaces(); console.log("얼굴 감지 루프 시작됨"); } else { console.error("Detector가 로드되지 않아 감지를 시작할 수 없습니다."); statusDiv.innerText = "오류: 모델 로드 실패로 감지 시작 불가."; } } catch (error) { console.error("main 함수 초기화 실패:", error); statusDiv.innerText = "초기화 중 심각한 오류 발생."; }
        }

        // 페이지 로드 완료 후 메인 함수 실행
        window.addEventListener('load', () => { /* ... 이전 디버깅 코드와 동일 ... */
            console.log("페이지 로드 완료"); main();
        });

    </script>
</body>
</html>
